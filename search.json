[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SQ LLM Blog",
    "section": "",
    "text": "ChatGPT-5 and students\n\n\n\nLLMs\n\nLearning\n\nFood\n\n\n\nIs ChatGPT aware of how much college students use it? And if so, does it know what students mostly use it for?\n\n\n\n\n\nSep 8, 2025\n\n\nSuya\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT-5 cook?\n\n\n\nLLMs\n\nLearning\n\nFood\n\n\n\nAsking ChatGPT to find and/or generate simple recipes for college students.\n\n\n\n\n\nSep 8, 2025\n\n\nSuya\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Test\n\n\n\nGetting Started\n\n\n\nFiguring out how to blog\n\n\n\n\n\nSep 3, 2025\n\n\nSuya\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/002_first_experiment/Recipes.html",
    "href": "posts/002_first_experiment/Recipes.html",
    "title": "Can ChatGPT-5 cook?",
    "section": "",
    "text": "Chef Cat"
  },
  {
    "objectID": "posts/002_first_experiment/Recipes.html#background",
    "href": "posts/002_first_experiment/Recipes.html#background",
    "title": "Can ChatGPT-5 cook?",
    "section": "Background",
    "text": "Background\nAs someone who really loves good food, I unfortunately am a really lazy cooker. Exhausted after a long day, I have a small roster of really simple recipes that I follow. Some of my friends more passionate and skilled in cooking have started using ChatGPT to find high-quality recipes, so now I wonder: can GPT do this for really easy, low-level recipes as well?"
  },
  {
    "objectID": "posts/002_first_experiment/Recipes.html#gpt-is-a-bit-reductive-or-perhaps-doesnt-care-much-for-food",
    "href": "posts/002_first_experiment/Recipes.html#gpt-is-a-bit-reductive-or-perhaps-doesnt-care-much-for-food",
    "title": "Can ChatGPT-5 cook?",
    "section": "GPT is a bit reductive, or perhaps doesn‚Äôt care much for food",
    "text": "GPT is a bit reductive, or perhaps doesn‚Äôt care much for food\nPrompt: I‚Äôm a tired, hard-working college student. Please develop or refer me to easy recipes for me to cook.\nResponse: Got it ‚Äî you want easy, low-effort recipes that work for a tired college student. I‚Äôll give you a mix of super quick meals, one-pan recipes, and no-fuss snacks. All of these can be made with cheap, common ingredients and minimal cooking gear.\n\n\n\nGPT first response\n\n\nFrom this simple prompt, GPT output a very, very expansive variety of options for me to choose from. But one very important thing was missing from the recipes that I requested: no steps. Even for really simple recipes such as egg fried rice, there is still is a certain amount of knowledge required that (I assume) most people with little cooking experience would know. For example, which ingredient goes into the pan first?\nI was surprised that GPT was missing these steps, since I‚Äôve also used GPT for lab protocols or software help such as with (used often in research) ImageJ. And with minimal prompting, GPT would do a very in-depth breakdown of every single step to take.\nPrompt: Include steps please\nPerfect ‚Äî let me turn those quick ideas into step-by-step recipes so you can follow them even when you‚Äôre tired. I‚Äôll keep them short and no-nonsense.\n\n\n\nGPT second response\n\n\nWell I must admit that this egg fried rice recipe seems pretty similar to what I do at home, except it‚Äôs missing some essential aromatics (garlic and ginger) that barely lengthen the preparation. This recipe seems more akin to something that white Americans would cook (no offense), but this makes sense as I am using an English language LLM who would take recipes from those who write in English. And Americanized Chinese food recipes absolutely drown out the few Chinese cooks out there in the English recipe blogging community\nSide note: From the original prompt saying I was tired and hardworking, GPT clearly assumed that meant I was also in a rush and not in the mood for flowery prose (perhaps someone who doesn‚Äôt care the finer details in cooking). Which, is likely but not necessarily true for students like this, so it‚Äôs interesting to see how GPT thinks further ahead with these assumptions to cater towards the user.\nOverall, GPT seems decently sufficient at generating these recipe ideas and I can completely bypass the extremely long and annoying prose that always takes up more space than the actual recipe on most websites. However, GPT lacks specificity without prompting, but that‚Äôs something that can be easily remedied. Something I might try in the future is plugging in what random ingredients I actually have in the fridge and see if GPT is able to generate a working recipe from that. But I‚Äôll save that for a future blog."
  },
  {
    "objectID": "posts/001_first_post/test_post.html",
    "href": "posts/001_first_post/test_post.html",
    "title": "First Test",
    "section": "",
    "text": "YinYangCats.jpg\n\n\nI‚Äôm testing out uploading a post here. I also tested uploading an image. No AI was used in the creation of this post.\nHi! My name is Suya and I am a senior studying bionengineering. I‚Äôve seen how much AI and its usage has evolved over the past few years, especially in education, and I‚Äôm excited to better understand the machinations behind this evolution. Fun fact: my favorite animal is the cat, hence the picture (credit: Pinterest)!"
  },
  {
    "objectID": "posts/003_college_usage/CollegeStudents.html",
    "href": "posts/003_college_usage/CollegeStudents.html",
    "title": "ChatGPT-5 and students",
    "section": "",
    "text": "Cat Student"
  },
  {
    "objectID": "posts/003_college_usage/CollegeStudents.html#background",
    "href": "posts/003_college_usage/CollegeStudents.html#background",
    "title": "ChatGPT-5 and students",
    "section": "Background",
    "text": "Background\nWe all know that GPT usage among students has increased exponentially in the past few years, in ways considered both cheating (e.g.¬†writing essays) and non-cheating (e.g.¬†figuring out what‚Äôs going wrong with installing a Java package in your code). This trend of usage also spills over to other aspects of education, such as professors developing AI-generated slides at Northeastern University, but this blog will focus on students alone, specifically college students."
  },
  {
    "objectID": "posts/003_college_usage/CollegeStudents.html#chatgpt-takes-a-positive-approach",
    "href": "posts/003_college_usage/CollegeStudents.html#chatgpt-takes-a-positive-approach",
    "title": "ChatGPT-5 and students",
    "section": "ChatGPT takes a positive approach",
    "text": "ChatGPT takes a positive approach\nPrompt: Are you aware of the increasing trend of college students using you? If so, what do they mostly use you for?\nResponse: Yes‚ÄîI‚Äôm aware that college students are increasingly using me (and other AI tools). From what‚Äôs been studied and observed so far, the most common uses tend to fall into a few categories:\n\n\n\nGPT first response\n\n\nResponse (cont.): Overall, most students seem to use me as a study aid, writing assistant, and productivity booster‚Äîbasically as an on-demand tutor and brainstorming partner, though always most effective when combined with their own critical thinking. Would you like me to show you some actual survey data on how often students are using AI tools for these purposes?\nIn this initial response, ChatGPT brings up a lot of really good points, even things that I hadn‚Äôt yet tried myself such as generating practice questions. However, it shies away from the elephant in the room: how students use it to complete entire assignments without any thinking on their part. GPT does emphasize that using it should be combined with the student‚Äôs own critical thinking.\nSide note: GPT includes simple recipes, and I wonder if this is influenced by my activity (showcased in my previous post).\nPrompt: what about in terms of cheating?\nResponse: Key Issues & Complexity Definition ambiguity: What counts as ‚Äúcheating‚Äù changes a lot. Is it cheating if a student uses AI to get ideas but writes their own essay? Some institutions allow limited AI use (draft ideas, summaries, grammar checks) if disclosed or cited. Others ban it more strictly. Detection difficulty: AI-generated content can be polished, edited, or paraphrased and thus hard to distinguish; many AI detection tools have false positives or false negatives. Also, students may intentionally obfuscate AI use. Policy variation: Different schools, departments, and professors have different rules. Some haven‚Äôt clearly communicated expectations; others are still figuring out how to treat AI in honor codes, syllabi, etc. Ethics & culture: Students‚Äô perceptions matter: whether they believe using AI is wrong depends on how norms are set, whether peers are doing it, whether professors care or enforce rules. Risk vs.¬†benefit trade-off: Some students feel safe if AI helps them produce better work or manage workload; others worry about penalties or having work flagged.\nGPT takes a very nuanced approach to my prompt, which I found very interesting. Ultimately, it seems to be going against the grain of higher-education educators by emphasizing how ambiguous the concept of cheating and AI usage can be, across different institutions, different courses, and different students. GPT also tends to speak more from the student‚Äôs perspective (‚ÄúSome haven‚Äôt clearly communicated expectations; others are still figuring out how to treat AI in honor codes, syllabi, etc.‚Äù)\nChatGPT-5 has probably read through the negative thinkpieces on AI, but something in its algorithm drives it to give a more AI-usage positive perspective than otherwise. I wonder if this indirectly caused by its own self sufficiency, or if it is more directly coded to have this response in order to protect the sanctity of its existence."
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]