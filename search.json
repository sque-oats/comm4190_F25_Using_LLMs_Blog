[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Suya’s COMM4190 Blog",
    "section": "",
    "text": "AI and Art\n\n\n\nLLMs\n\nAI Opinions\n\n\n\nIn the role of an art critic, what are the opinions of ChatGPT-5 on art?\n\n\n\n\n\nSep 17, 2025\n\n\nSuya\n\n\n\n\n\n\n\n\n\n\n\n\nDoom and Gloom = More Hype?\n\n\n\nLLMs\n\nAI Opinions\n\n\n\nThe authors of The AI Con discuss how terror of AI is used to effectively generate more investment in AI. Does ChatGPT-5 agree or disagree?\n\n\n\n\n\nSep 13, 2025\n\n\nSuya\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT-5 and college students\n\n\n\nLLMs\n\nLearning\n\nEducation\n\n\n\nIs ChatGPT aware of how much college students use it? And if so, does it know what students mostly use it for?\n\n\n\n\n\nSep 10, 2025\n\n\nSuya\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT-5 cook?\n\n\n\nLLMs\n\nLearning\n\nFood\n\n\n\nAsking ChatGPT to find and/or generate simple recipes for college students.\n\n\n\n\n\nSep 8, 2025\n\n\nSuya\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Test\n\n\n\nGetting Started\n\n\n\nFiguring out how to blog\n\n\n\n\n\nSep 3, 2025\n\n\nSuya\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/002_first_experiment/Recipes.html",
    "href": "posts/002_first_experiment/Recipes.html",
    "title": "Can ChatGPT-5 cook?",
    "section": "",
    "text": "Chef Cat"
  },
  {
    "objectID": "posts/002_first_experiment/Recipes.html#background",
    "href": "posts/002_first_experiment/Recipes.html#background",
    "title": "Can ChatGPT-5 cook?",
    "section": "Background",
    "text": "Background\nAs someone who really loves good food, I unfortunately am a really lazy cooker. Exhausted after a long day, I have a small roster of really simple recipes that I follow. Some of my friends more passionate and skilled in cooking have started using ChatGPT to find high-quality recipes, so now I wonder: can GPT do this for really easy, low-level recipes as well?"
  },
  {
    "objectID": "posts/002_first_experiment/Recipes.html#gpt-is-a-bit-reductive-or-perhaps-doesnt-care-much-for-food",
    "href": "posts/002_first_experiment/Recipes.html#gpt-is-a-bit-reductive-or-perhaps-doesnt-care-much-for-food",
    "title": "Can ChatGPT-5 cook?",
    "section": "GPT is a bit reductive, or perhaps doesn’t care much for food",
    "text": "GPT is a bit reductive, or perhaps doesn’t care much for food\nPrompt: I’m a tired, hard-working college student. Please develop or refer me to easy recipes for me to cook.\nResponse: Got it — you want easy, low-effort recipes that work for a tired college student. I’ll give you a mix of super quick meals, one-pan recipes, and no-fuss snacks. All of these can be made with cheap, common ingredients and minimal cooking gear.\n\n\n\nGPT first response\n\n\nFrom this simple prompt, GPT output a very, very expansive variety of options for me to choose from. But one very important thing was missing from the recipes that I requested: no steps. Even for really simple recipes such as egg fried rice, there is still is a certain amount of knowledge required that (I assume) most people with little cooking experience would know. For example, which ingredient goes into the pan first?\nI was surprised that GPT was missing these steps, since I’ve also used GPT for lab protocols or software help such as with (used often in research) ImageJ. And with minimal prompting, GPT would do a very in-depth breakdown of every single step to take.\nPrompt: Include steps please\nPerfect — let me turn those quick ideas into step-by-step recipes so you can follow them even when you’re tired. I’ll keep them short and no-nonsense.\n\n\n\nGPT second response\n\n\nWell I must admit that this egg fried rice recipe seems pretty similar to what I do at home, except it’s missing some essential aromatics (garlic and ginger) that barely lengthen the preparation. This recipe seems more akin to something that white Americans would cook (no offense), but this makes sense as I am using an English language LLM who would take recipes from those who write in English. And Americanized Chinese food recipes absolutely drown out the few Chinese cooks out there in the English recipe blogging community\nSide note: From the original prompt saying I was tired and hardworking, GPT clearly assumed that meant I was also in a rush and not in the mood for flowery prose (perhaps someone who doesn’t care the finer details in cooking). Which, is likely but not necessarily true for students like this, so it’s interesting to see how GPT thinks further ahead with these assumptions to cater towards the user.\nOverall, GPT seems decently sufficient at generating these recipe ideas and I can completely bypass the extremely long and annoying prose that always takes up more space than the actual recipe on most websites. However, GPT lacks specificity without prompting, but that’s something that can be easily remedied. Something I might try in the future is plugging in what random ingredients I actually have in the fridge and see if GPT is able to generate a working recipe from that. But I’ll save that for a future blog."
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/001_first_post/test_post.html",
    "href": "posts/001_first_post/test_post.html",
    "title": "First Test",
    "section": "",
    "text": "YinYangCats.jpg\n\n\nI’m testing out uploading a post here. I also tested uploading an image. No AI was used in the creation of this post.\nHi! My name is Suya and I am a senior studying bionengineering. I’ve seen how much AI and its usage has evolved over the past few years, especially in education, and I’m excited to better understand the machinations behind this evolution. Fun fact: my favorite animal is the cat, hence the picture (credit: Pinterest)!"
  },
  {
    "objectID": "posts/003_college_usage/CollegeStudents.html",
    "href": "posts/003_college_usage/CollegeStudents.html",
    "title": "ChatGPT-5 and college students",
    "section": "",
    "text": "Cat Student"
  },
  {
    "objectID": "posts/003_college_usage/CollegeStudents.html#background",
    "href": "posts/003_college_usage/CollegeStudents.html#background",
    "title": "ChatGPT-5 and college students",
    "section": "Background",
    "text": "Background\nWe all know that GPT usage among students has increased exponentially in the past few years, in ways considered both cheating (e.g. writing essays) and non-cheating (e.g. figuring out what’s going wrong with installing a Java package in your code). This trend of usage also spills over to other aspects of education, such as professors developing AI-generated slides at Northeastern University, but this blog will focus on students alone, specifically college students."
  },
  {
    "objectID": "posts/003_college_usage/CollegeStudents.html#chatgpt-takes-a-positive-approach",
    "href": "posts/003_college_usage/CollegeStudents.html#chatgpt-takes-a-positive-approach",
    "title": "ChatGPT-5 and college students",
    "section": "ChatGPT takes a positive approach",
    "text": "ChatGPT takes a positive approach\nPrompt: Are you aware of the increasing trend of college students using you? If so, what do they mostly use you for?\nResponse: Yes—I’m aware that college students are increasingly using me (and other AI tools). From what’s been studied and observed so far, the most common uses tend to fall into a few categories:\n\n\n\nGPT first response\n\n\nResponse (cont.): Overall, most students seem to use me as a study aid, writing assistant, and productivity booster—basically as an on-demand tutor and brainstorming partner, though always most effective when combined with their own critical thinking. Would you like me to show you some actual survey data on how often students are using AI tools for these purposes?\nIn this initial response, ChatGPT brings up a lot of really good points, even things that I hadn’t yet tried myself such as generating practice questions. However, it shies away from the elephant in the room: how students use it to complete entire assignments without any thinking on their part. GPT does emphasize that using it should be combined with the student’s own critical thinking.\nSide note: GPT includes simple recipes, and I wonder if this is influenced by my activity (showcased in my previous post).\nPrompt: what about in terms of cheating?\nResponse: Key Issues & Complexity Definition ambiguity: What counts as “cheating” changes a lot. Is it cheating if a student uses AI to get ideas but writes their own essay? Some institutions allow limited AI use (draft ideas, summaries, grammar checks) if disclosed or cited. Others ban it more strictly. Detection difficulty: AI-generated content can be polished, edited, or paraphrased and thus hard to distinguish; many AI detection tools have false positives or false negatives. Also, students may intentionally obfuscate AI use. Policy variation: Different schools, departments, and professors have different rules. Some haven’t clearly communicated expectations; others are still figuring out how to treat AI in honor codes, syllabi, etc. Ethics & culture: Students’ perceptions matter: whether they believe using AI is wrong depends on how norms are set, whether peers are doing it, whether professors care or enforce rules. Risk vs. benefit trade-off: Some students feel safe if AI helps them produce better work or manage workload; others worry about penalties or having work flagged.\nGPT takes a very nuanced approach to my prompt, which I found very interesting. Ultimately, it seems to be going against the grain of higher-education educators by emphasizing how ambiguous the concept of cheating and AI usage can be, across different institutions, different courses, and different students. GPT also tends to speak more from the student’s perspective (“Some haven’t clearly communicated expectations; others are still figuring out how to treat AI in honor codes, syllabi, etc.”)\nChatGPT-5 has probably read through the negative thinkpieces on AI, but something in its algorithm drives it to give a more AI-usage positive perspective than otherwise. I wonder if this indirectly caused by its own self sufficiency, or if it is more directly coded to have this response in order to protect the sanctity of its existence…"
  },
  {
    "objectID": "posts/004_doom_hype/doom.html",
    "href": "posts/004_doom_hype/doom.html",
    "title": "Doom and Gloom = More Hype?",
    "section": "",
    "text": "Praying Cat"
  },
  {
    "objectID": "posts/004_doom_hype/doom.html#the-ai-cons-opinion-on-ai-doom",
    "href": "posts/004_doom_hype/doom.html#the-ai-cons-opinion-on-ai-doom",
    "title": "Doom and Gloom = More Hype?",
    "section": "The AI Con’s Opinion on “AI Doom”",
    "text": "The AI Con’s Opinion on “AI Doom”\n“The AI Con” is the book I’m living with for the rest of this class, and it started off swinging. Through its powerful and argumentative language, an early opinon of this book that has really stood out to me is how AI startups use extreme negative connotations, not just positive, to its advantage.\nThe book argues that tapping into the previosuly manufactured scare factors of AI, such as through stories like The Matrix, works to inflate the perceived worth of those in charge of developing AI.\n“I will be the savior that prevents this from happening to humanity, believe in me!”"
  },
  {
    "objectID": "posts/004_doom_hype/doom.html#gpt-5s-opinion",
    "href": "posts/004_doom_hype/doom.html#gpt-5s-opinion",
    "title": "Doom and Gloom = More Hype?",
    "section": "GPT-5’s Opinion",
    "text": "GPT-5’s Opinion\nThere is such a wide spectrum of opinions on AI as a whole, and I bet there are a lot of differing opinions on this very specific topic. So I wondered, what does AI itself think about this?\nPrompt &gt; What do you think about doom coverage on AI (emphaisizing The Matrix-esque futures), and how do you think this impacts the growth of the AI industry?\nResponse &gt; That’s a great question — it cuts across media studies, public perception, and industry strategy. Here are some angles to consider:\n\nDoom Coverage and Cultural Narratives When outlets emphasize The Matrix-style AI dystopias, they tap into a long tradition of techno-apocalyptic storytelling. These narratives resonate because they dramatize anxieties about control, autonomy, and human obsolescence. They simplify complex technical debates into familiar tropes of “man vs. machine.” Pros: Easy for the public to understand, sparks awareness of real ethical risks. Cons: Can distort nuance by framing AI primarily as existential threat rather than a multifaceted tool. \nPublic Perception and Trust Doom-heavy coverage often polarizes public opinion: Skeptics & critics may use these narratives to demand stronger regulation and slow down deployment. Optimists & adopters may dismiss them as hype, but still face public fear or mistrust when rolling out AI tools (e.g., in healthcare or education). The net effect is heightened uncertainty, which can either motivate caution or fuel backlash against AI adoption. \nIndustry Growth Dynamics The impact on the AI industry is nuanced: Short-term drag: Public mistrust can slow down user adoption (e.g., patients reluctant to accept AI diagnoses, students wary of “AI teachers”). It can also encourage heavy-handed regulation that makes scaling harder. Long-term acceleration: Paradoxically, doom coverage can drive investment. Investors and governments may see AI as powerful (and therefore high-stakes) technology — worth betting on, shaping, and controlling. Think of how nuclear fears led to both arms control treaties and massive investment in nuclear energy and defense. \nRegulatory and Research Outcomes Doom narratives have already influenced high-level policy debates (e.g., US and EU AI regulation citing “existential risk”). This helps justify funding for AI safety research, explainability, and standards — creating whole new industry niches. \nCompetitive Framing  Companies often lean into or against doom narratives depending on their goals: Big AI labs sometimes amplify risk discourse (to signal responsibility and justify centralized control of frontier models).  Startups may position themselves as “democratizing” AI to counteract fears and emphasize accessibility.  ✅ Bottom line: Doom coverage doesn’t stop AI industry growth — it reframes it. While it introduces friction (public fear, potential regulation), it also reinforces the perception that AI is transformative and worth heavy investment. Over time, this mix tends to stabilize into cautious but continued growth, with safety becoming a major parallel industry. \n\nGPT-5 ultimately takes a very neutral approach, which I found interesting because I expected something more negative as something that on the surface just speaks against the future of AI. This has showed that that GPT-5 is capable of greater reasoning and nuance than I have previously believed, and ironically, makes it a bit more scary. It’s interesting to note that the opinion of “The AI Con” represent a perfect half of Point #3 and #5 in GPT-5’s response."
  },
  {
    "objectID": "posts/005_art/art.html",
    "href": "posts/005_art/art.html",
    "title": "AI and Art",
    "section": "",
    "text": "Cat in Museum\n\n\nInspiration\nI’m currently taking a class called “Art of the Web,” a design course centered around digital art. This goes beyond pixelated art, thinking of e-mails, websites, and ASCII code as art mediums. As art and its development has moved to computers and these techy platforms, I began to wonder, has there been a sort of “reverse” exchange? Can machines admire or “feel” from art such as humans do?\nA Speculative Analysis\nPrompt &gt; You are in the role of a professional art critic. Please provide succinct and clear opinions on these art pieces.   \nIn terms of human-made art pieces, I chose to only use art pieces I found on Pinterest, in the hopes that being able to recognize a famous art piece (e.g. Mona Lisa) wouldn’t impact GPT-5’s “opinion”. For the AI-generated art, that was from generated from GPT-5 with the prompt: generate me an artwork of a man surfboarding.\nResponse &gt; Here are my succinct critiques of the three works you shared:  1. Surreal Goldfish Dreamscape A strikingly surreal image blending dream and nature: the reclining face merges with grassy hills, while fish swim inside a fragile bubble of breath. Its charm lies in playful scale inversions (tiny cows below, monumental face above) and the sense of subconscious fluidity. The work feels whimsical yet contemplative, though its symbolism risks being overly literal if read only as “daydreaming.” The delicate watercolor-like textures soften the surrealism into something poetic. 2. Seascape with Boats (Van Gogh–style) This seascape captures both turbulence and lightness through restless brushwork and vivid color contrasts. The frothy foreground waves surge toward the viewer, while boats in the distance anchor the scene with calm human presence. The painting’s strength is in its kinetic rhythm — strokes that echo the sea’s perpetual motion. Yet, the composition leaves much negative space in the sky, making it slightly less balanced than Van Gogh’s strongest marine works. Still, the sea’s vitality is palpable.  3. Surfer in the Wave An energetic, heroic depiction of a surfer at the crest of a curling wave. The figure is sculptural, almost classical, with muscles modeled in bold light and shadow — reminiscent of Romanticism’s admiration for man versus nature. The ocean’s brushstrokes amplify dynamism, though the scene leans toward idealization: more illustration than intimate encounter with the sea. Its appeal lies in its immediacy and athletic power rather than subtle mood.  👉 Overall: The first piece is whimsical-surreal and poetic. The second is impressionistic, kinetic, and elemental. The third is dramatic, heroic, and illustrative.\nInterestingly, AI opinion’s on the AI-generated work was the most positive. Only in opinion #1 does GPT-5 explicitly the feelings that the artwork evokes in the viewer. Generally GPT-5’s opinions rely more on analysis of technicality and physicality rather than “vibes” and feelings. However, vague these vibes and feelings may be, I believe it to be something essential in our own human analysis of artwork, but perhaps at least this language will be incorporated into GPT-5 and other LLM’s capabilities in the near future.\nSide note: I asked GPT-5 which single artwork appeared generated out of the 3. GPT-5 answered that art piece #1 (human-made) does. This interests me in further experimentation on this subject.\nSide note: I generally dislike the concept of AI-generated art, since (at least to me) it will always lack a certain human warmth. However, I’ve noticed a huge jump in the technical quality of works compared to before where artworks generated by general prompts like mine would result in something round and shiny, which is something I find intriguing and also a bit more scared for the art industry."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "BE 2026"
  }
]