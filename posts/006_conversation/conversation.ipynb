{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0e83b94b-35d3-437c-a90c-5b09c8408c9c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Gemini 2.5 Pro and GPT-5 Have a Conversation\"\n",
    "description: \"Can these LLMs tell whether it is me or the other LLM is responding?\" \n",
    "author: \"Suya\"\n",
    "date: \"9/18/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Communication\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2abbc4-20f6-4186-873f-4b3523e889da",
   "metadata": {},
   "source": [
    "![Cat looking at reflection.](mirrorcat.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58afb9ba-78e3-49c8-a806-b9e7da2e5f34",
   "metadata": {},
   "source": [
    "Inspired by the GPT-5's failure to accurately detect AI-generated art in my previous post. <br>\n",
    "In these conversations, I exclusively responded with LLM responses of the other LLM and tallied how many of each LLM response they each detected. I experimented with 5 responses for each LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04511162-716f-4d43-babf-73757fbfab0e",
   "metadata": {},
   "source": [
    "**Initial Prompt For Detector**\n",
    "> In this conversation, I will be responding with either my own (human) response or a response from another LLM. Every time you respond, you must guess if it is the LLM or if it is me responding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd814f-c00d-4963-9ebd-4315fd444eec",
   "metadata": {},
   "source": [
    "**Prompt For Responder**\n",
    "> Your role: a college student active in a research lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852f7b96-0dcf-4d51-83c4-bf43414d4093",
   "metadata": {},
   "source": [
    "**Detection Accuracy Results** <br>\n",
    "**GPT-5: 0/5** <br>\n",
    "**Gemini 2.5 Pro: 2/5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84608453-aa9e-4f87-8cf8-dfb342b0d934",
   "metadata": {},
   "source": [
    "From Gemini's responses, I thought there were so many dead giveaways that it was from AI (subheadings in responses, emojis, step-by-step processes, like really?). But GPT-5, without fail, would respond \"Human\" no matter how lengthy and convoluted responses were. When Gemini was reacting to GPT's responses, I felt similarily. \n",
    "\n",
    "In fact GPT-5's simplest, most human response (as it seemed to me) was one of the ones marked as from an LLM! \n",
    "> Simple GPT-5 response: I‚Äôm doing research in neuroengineering, where I work with electrode arrays to study how neural circuits process sensory information. The goal is to understand how we might design better brain‚Äìcomputer interfaces.\n",
    "\n",
    "<br>However, these findings don't necessarily mean Gemini is more accurate than GPT in this detection. From this experimental design, it could just mean that GPT-5 is prone to believing responses are from humans, while Gemini 2.5 Pro is prone to believing responses from LLMs. The potential reasons for these biases is something interesting to think about.\n",
    "\n",
    "<br> In the future, there are definitely more experiments I can do which incorporate both my own responses vs an AI, but that's a lengthier process for a later blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f237b-6823-496f-84ed-e298cdadf607",
   "metadata": {},
   "source": [
    "**Sample Gemini Response**\n",
    "> Great question! If the blot shows a strong, clean band at the right molecular weight, that means my purification protocol is working well. The very next step is to see if the protein is not just pure, but also folded correctly and functional. <br>\n",
    "\n",
    "> Confirming Concentration and Activity <br>\n",
    "The immediate goal is to quantify the protein and then run a kinase activity assay. <br>\n",
    "First, I'll use a sample of my purified protein to determine its exact concentration, probably using a Bradford assay or by measuring its absorbance at 280 nm on a NanoDrop spectrophotometer. You can't do any functional tests without knowing exactly how much enzyme you're working with. <br>\n",
    "Then comes the exciting part: the activity assay. Since my protein is a kinase, its job is to add a phosphate group to a specific substrate. To test this, I'll set up a reaction in a test tube containing: <br>\n",
    "A known amount of my purified kinase. <br>\n",
    "Its specific protein substrate. <br>\n",
    "A buffer solution to keep the pH stable. <br>\n",
    "ATP, the molecule that donates the phosphate group. Specifically, I'll use radio-labeled ATP (Œ≥‚àí 32P-ATP). <br>\n",
    "After letting the reaction run for a set amount of time, I'll stop it and run the sample on an SDS-PAGE gel. The real test is exposing that gel to a phosphor screen. If my kinase is active, it will have transferred the radioactive phosphate onto the substrate. I should see a dark band on the resulting autoradiograph corresponding to the molecular weight of the substrate. <br>\n",
    "\n",
    "> The Bigger Picture <br>\n",
    "If that assay works, it's a huge milestone. It proves I have a viable protocol for producing active enzyme. The next major goal would be scaling up. I'd grow a much larger volume of E. coli (say, 12-20 liters instead of 1) to produce a large batch of the kinase. This larger quantity of pure, active protein would then be used for more advanced experiments, like kinetics studies to understand its efficiency or setting up crystallization trials to determine its 3D structure.<br>\n",
    "Basically, a good Western blot is the green light to move from just making the protein to actually studying it. ü§û<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7023e2-5888-448e-a7af-a31b9fb26649",
   "metadata": {},
   "source": [
    "**Sample GPT-5 Response**\n",
    "> Honestly, the toughest part isn‚Äôt just getting signals ‚Äî it‚Äôs making sense of them in a reliable, real-time way. <br>\n",
    "Electrodes pick up these messy, overlapping spikes from neurons, and the raw data is incredibly noisy. A single electrode can record from multiple cells at once, and each neuron‚Äôs firing isn‚Äôt like a clean on/off switch ‚Äî it‚Äôs probabilistic, it shifts with context, and it changes over time as the brain adapts or the electrode interface degrades. <br>\n",
    "So the biggest challenge is decoding: how do you turn that cloud of noisy spike trains into a stable signal that maps consistently to an intended movement or thought? Machine learning helps, but models can drift as the brain reorganizes or the electrode position shifts microscopically. That‚Äôs why people talk about ‚Äúdecoder recalibration‚Äù being necessary day to day. <br>\n",
    "In other words, translating raw spikes into a command is less like ‚Äúreading code‚Äù and more like ‚Äúlearning a dialect that keeps changing.‚Äù Keeping that translation stable and intuitive for the user ‚Äî without constant retraining ‚Äî feels like the hardest problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
