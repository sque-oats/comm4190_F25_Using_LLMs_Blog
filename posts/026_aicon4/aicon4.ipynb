{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ce7be68e-8187-433d-9e24-c85b4b203c99",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Clever Hans\"\n",
    "description: \"Current Thoughts on the AI Con. Review #4\" \n",
    "author: \"Suya\"\n",
    "date: \"12/12/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - The AI Con\n",
    "  - Book Review\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5768daf5-21aa-47a7-86c6-a451fd0d9722",
   "metadata": {},
   "source": [
    "![Drawing of Cat with Book](aicon4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975736de-51ae-4a9e-be4a-a7ab703bcebc",
   "metadata": {},
   "source": [
    "Further reading in *The AI Con* has continued to pile examples (sometimes so many that it makes for tedious reading, but it's still informative) of the many ways AI is being trickled into systems. For example, the judicial system and its racialized calculation of reoffending. In so many ways, AI systems are being implemented in ways that act as imperfect band-aids, enabling those in power avoid working hard at solving the roots of these issues. Two topics discussed have been really interesting to me personally, which I talk about further below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef60270-7310-4446-b40e-22a0118798fd",
   "metadata": {},
   "source": [
    "## Measures of Intelligence in Medicine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4390db-01c4-48cd-9617-c5928a55a3e0",
   "metadata": {},
   "source": [
    "As a pre-med student, I've heard a lot of things on AI in medicine. Both good and bad. But *The AI Con* disucsses some instances of AI in medicine that I hadn't thought of or heard of before, and of course these instances tend to be negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e297eb-6db1-4681-b302-26848ea8c4d9",
   "metadata": {},
   "source": [
    "This past spring, I took the MCAT, a required test of medical school admissions. It's really challenging, and I don't doubt that AI would be able to score excellently if not perfectly on this exam. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32e19e6-cfa6-40b9-9063-8181a39d7d09",
   "metadata": {},
   "source": [
    "A horse named Clever Hans was once trained on being able to \"solve\" arithmetic, but this was only accopmlished by the owner training the horse to recognize some certain physical cues rather than it being able to truly understand mathematics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3798df7-374f-4d1f-9d00-e21669ada4fe",
   "metadata": {},
   "source": [
    "![Clever Hans \"solving\" some arithmetic](cleverhans.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43358d2-ea79-42a6-8ab1-877a3fc52841",
   "metadata": {},
   "source": [
    "*The AI Con* discusses how AI often emulates the concept of Clever Hans. It seems so smart, but in the end it's not really thinking at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b10879-3df1-42d4-b048-263b17140da0",
   "metadata": {},
   "source": [
    "In terms of medicine, this is evidenced by a gripe many people have with actual human medical school applicants too: scoring well on the MCAT doesn't mean they'll be a doctor. Doctors need empathy, social awareness, should be able to think quickly on their feet, and remain calm in stressful situations. Anyone who scores well on the MCAT just shows they're good test-takers. After all, many smart people with good memories and an abundance of knowledge can get so nervous during the MCAT they score poorly as well. It's a very narrow metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4cd1a3-98c6-4fff-af04-3fe0dd1de55d",
   "metadata": {},
   "source": [
    "Yet many AI companies hype up the ability of AI in medicine just because they score on Steps 1 and 2, two medical licensing exams that students are required to take in medical school on the pathway to become doctors. Just more tests. And this somehow translates into them being able to function as doctors or even therapists?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f50075-dfe7-4172-b38d-7c2ad0d8b6ab",
   "metadata": {},
   "source": [
    "## Education Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e08cbc0-dc40-4b25-b442-546d7dc79853",
   "metadata": {},
   "source": [
    "Interestingly, this section included something that I completely disagree with. This is the first time in this book I've experienced this. So *The AI Con* says that actually most students don't use ChatGPT, or even know what GPT is (75% don't know GPT is the statistic they provided, as of 2023 to be fair). This is used to cast light on how professors fail to understand how students use GPT. But this statistic, as a student, is just absolutely not true. Even back in 2022 when it was first bursting on the scene, everyone knew what it was by the end of the year. By 2023, most students I knew were using in some capacity, even if it's not cheating. To say 3/4 of students didn't know what it was by 2023 is just crazy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc1e76-0e6c-4c28-9b6b-fe32db4ed711",
   "metadata": {},
   "source": [
    "But I do agree with a broader point the authors were trying to make, which was that AI paranoia by professors and educators often led to combative yet ineffective approaches. In a previous post I made, **\"Gemini 2.5 Pro and GPT-5 Have a Conversation,\"** these LLM models were widly inaccurate at guessing whether it was a human or another LLM responding to them in conversation. This clearly remains the case in essay writing as well, yet using AI to detect AI writing seems to be a common thing in education."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddabde6-703b-43bd-810b-1761cee61ddb",
   "metadata": {},
   "source": [
    "The last thing I want to note, is that the authors worry about how deeply AI is being integrated into some more mundane aspects of education. For example, grading assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db026be-7494-4c4b-a3c1-b044e2b6c897",
   "metadata": {},
   "source": [
    "I recently watched a documentary on how AI is being integrated into Chinese education. AI imaging software monitors how engaged students are in class through hidden cameras (yikes) and also does do automated grading of paper assignments. High-tech, but also imperfect. For multiple choice assignments, I can maybe understand (although I just experienced Scantron throughout my high school years), but for written assignments, it's less robust. After all, students like me may have below-average handwriting. What happens when these are misinterpreted then? Teachers shouldn't offload all of this work into AI, and as I saw in the documentary, teachers check the assignments manually after AI grading anyway, in case the AI makes mistakes..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
